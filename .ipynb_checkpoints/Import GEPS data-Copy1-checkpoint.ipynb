{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Brett: invertible reshaping (spatial/temporal)\n",
    "- Brett: refactor model code into Python library\n",
    "- Josh: simple PCA clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import scipy.io as io\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import (signal, io)\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Dense, Conv1D, GRU, LSTM, Recurrent, Bidirectional,\n",
    "                          TimeDistributed, Dropout, Flatten, RepeatVector, Reshape)\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "gpu_opts = tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.4))\n",
    "K.set_session(tf.Session(config=gpu_opts))\n",
    "#K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    f = io.matlab.loadmat(data_path)\n",
    "    loop_data = f['Loopdata_mixed'][()]\n",
    "    X = loop_data.reshape(loop_data.shape[0]*loop_data.shape[0],-1)\n",
    "    X -= np.nanmean(X)\n",
    "    X[np.where(np.isfinite(x)==0)] = 0\n",
    "    X /= np.std(X)\n",
    "    X = np.atleast_3d(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_run_id(layer_type, size, num_layers, embedding, lr, drop_frac, batch_size, **kwargs):\n",
    "    return (f\"{layer_type}{size:03d}_x{num_layers}_emb{embedding:03d}_{lr:1.0e}\"\n",
    "            f\"_drop{int(100 * drop_frac)}_batch{batch_size}\").replace('e-', 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_auto(layer, size, num_layers, embedding, n_step, drop_frac=0., bidirectional=True,\n",
    "             **kwargs):\n",
    "    if bidirectional:\n",
    "        wrapper = Bidirectional\n",
    "    else:\n",
    "        wrapper = lambda x: x\n",
    "    model = Sequential()\n",
    "    model.add(wrapper(layer(size, return_sequences=(num_layers > 1)),\n",
    "                        input_shape=(n_step, 1)))\n",
    "    for i in range(1, num_layers):\n",
    "        model.add(wrapper(layer(size, return_sequences=(i < num_layers - 1))))\n",
    "        if drop_frac > 0.:\n",
    "            model.add(Dropout(drop_frac))\n",
    "    model.add(Dense(embedding, activation='linear', name='encoding'))\n",
    "    model.add(RepeatVector(n_step))\n",
    "    for i in range(num_layers):\n",
    "        model.add(wrapper(layer(size, return_sequences=True)))\n",
    "        if drop_frac > 0.:\n",
    "            model.add(Dropout(drop_frac))\n",
    "    model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5ddb265574c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-5ddb265574c5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arg_dict)\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m    \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTQDMCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0;32mfrom\u001b[0m \u001b[0margparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgumentParser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tqdm'"
     ]
    }
   ],
   "source": [
    " def main(arg_dict=None):\n",
    "    from keras.optimizers import Adam\n",
    "    import shutil\n",
    "    from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "    from keras_tqdm import TQDMCallback\n",
    "\n",
    "    from argparse import ArgumentParser, Namespace\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--data_path\", type=str, default='data/cleaned_data.mat')\n",
    "    parser.add_argument(\"--size\", type=int)\n",
    "    parser.add_argument(\"--num_layers\", type=int)\n",
    "    parser.add_argument('--embedding', type=int)\n",
    "    parser.add_argument(\"--drop_frac\", type=float, default=0.)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1024)\n",
    "    parser.add_argument(\"--n_cycles\", type=int, default=256)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float)\n",
    "    parser.add_argument(\"--layer_type\", type=str)\n",
    "    parser.add_argument(\"--N_train\", type=int)\n",
    "#    parser.add_argument(\"--patience\", type=int, default=20)\n",
    "    parser.add_argument('--bidirectional', dest='bidirectional', action='store_true')\n",
    "    parser.add_argument('--overwrite', dest='overwrite', action='store_true')\n",
    "    parser.add_argument('--log_dir', type=str, default='log')\n",
    "    parser.set_defaults(bidirectional=True, overwrite=False)\n",
    "    args = parser.parse_args(None if arg_dict is None else [])  # don't read argv if arg_dict present\n",
    "    if arg_dict:  # merge additional arguments w/ defaults\n",
    "        args = Namespace(**{**args.__dict__, **arg_dict})\n",
    "\n",
    "#    if args.layer_type == 'conv' and args.filter_length is None:\n",
    "#        parser.error(\"--layer_type {} requires --filter_length\".format(args.layer_type))\n",
    "\n",
    "    X = load_data(args.data_path, args.n_cycles)\n",
    "    if args.N_train:\n",
    "        train = np.arange(args.N_train)\n",
    "    else:\n",
    "        train = np.arange(len(X))\n",
    "\n",
    "    run = get_run_id(**args.__dict__)\n",
    "    log_dir = os.path.join(args.log_dir, run)\n",
    "    print(\"Logging to {}\".format(os.path.abspath(log_dir)))\n",
    "    weights_path = os.path.join(log_dir, 'weights.h5')\n",
    "    if os.path.exists(weights_path):\n",
    "        if args.overwrite:\n",
    "            print(f\"Overwriting {log_dir}\")\n",
    "            shutil.rmtree(log_dir, ignore_errors=True)\n",
    "        else:\n",
    "            raise ValueError(\"Model file already exists\")\n",
    "\n",
    "    layer = {'lstm': LSTM, 'gru': GRU, 'conv': Conv1D}[args.layer_type]\n",
    "    if issubclass(layer, Recurrent):\n",
    "        model = rnn_auto(layer, args.size, args.num_layers, args.embedding, n_step=X.shape[1],\n",
    "                         drop_frac=args.drop_frac)\n",
    "    else:\n",
    "        raise NotImplementedError(\"TODO convolutional\")\n",
    "    model.compile(Adam(args.lr), loss='mse')\n",
    "\n",
    "    history = model.fit(X[train], X[train], epochs=args.epochs, batch_size=args.batch_size,\n",
    "                        callbacks=[TQDMCallback(),\n",
    "                                   TensorBoard(log_dir=log_dir, write_graph=False),\n",
    "                                   ModelCheckpoint(weights_path)],\n",
    "                        verbose=False)\n",
    "\n",
    "    return X, model, history\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, model, history = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a55d79ee4b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mauto2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/joshuaagar/Amazon Drive/Data Analysis/NN of BEPS/auto2.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from auto2 import load_data\n",
    "\n",
    "load_data('data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "#model = keras.models.load_model('log/lstm128_x1_emb008_3m04_drop0_batch1024/weights.h5')\n",
    "\n",
    "encode_model = keras.models.Model(inputs=model.input,\n",
    "                                  outputs=[l for l in model.layers\n",
    "                                           if isinstance(l, keras.layers.core.Dense)][0].output)\n",
    "inds = np.arange(20, X.shape[0], 40)\n",
    "encoding = encode_model.predict(X[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(8)\n",
    "pca_model.fit(X.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, X.shape[0])\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.plot(model.predict(X[[i]])[0])\n",
    "plt.plot(pca_model.inverse_transform(pca_model.transform(X[[i]].squeeze())[0]))\n",
    "mse_rnn = np.mean((X[i] - model.predict(X[[i]])[0]) ** 2)\n",
    "mse_pca = np.mean((X[i].squeeze() - pca_model.inverse_transform(pca_model.transform(X[[i]].squeeze())[0])) ** 2)\n",
    "#plt.plot(X[i] - model.predict(X[[i]])[0])\n",
    "plt.title(f\"i={i}; MSE (RNN)={mse_rnn:1.5f}; MSE (PCA)={mse_pca:1.5f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pca_model.transform(X.squeeze())[inds]\n",
    "fig, ax = plt.subplots(8, 2, figsize=(8, 36))\n",
    "for j in range(encoding.shape[1]):\n",
    "    ax[j, 0].imshow(encoding[:, j].reshape((256, 256)), cmap='viridis')#, vmin=encoding.min(), vmax=encoding.max())\n",
    "    ax[j, 1].imshow(loadings[:, j].reshape((256, 256)), cmap='viridis')#, vmin=encoding.min(), vmax=encoding.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
